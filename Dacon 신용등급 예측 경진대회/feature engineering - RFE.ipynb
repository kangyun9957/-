{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9PLRXUaGxjq",
        "outputId": "be09c64e-d3ed-4df3-8f3b-e278f9f5f647"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2GBesNaAhsr",
        "outputId": "1562ff0d-7567-4360-8b5d-d618898c2eb9"
      },
      "source": [
        "!pip install kaggler"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggler in /usr/local/lib/python3.7/dist-packages (0.9.6)\n",
            "Requirement already satisfied: lightgbm in /root/.local/lib/python3.7/site-packages (from kaggler) (3.1.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (from kaggler) (0.90)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from kaggler) (0.29.23)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from kaggler) (2.5.0)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (from kaggler) (0.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from kaggler) (3.2.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from kaggler) (0.10.2)\n",
            "Requirement already satisfied: ml-metrics in /usr/local/lib/python3.7/dist-packages (from kaggler) (0.1.4)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from kaggler) (1.5.12)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm->kaggler) (0.36.2)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.7/dist-packages (from lightgbm->kaggler) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm->kaggler) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm->kaggler) (1.4.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.12)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (3.7.4.3)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.15.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (0.12.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (2.5.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.6.3)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (1.34.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (2.5.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->kaggler) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt->kaggler) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt->kaggler) (3.11.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt->kaggler) (2.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt->kaggler) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kaggler) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kaggler) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kaggler) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kaggler) (0.10.0)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from statsmodels->kaggler) (1.1.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->kaggler) (0.5.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggler) (2020.12.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggler) (5.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggler) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->kaggler) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->lightgbm->kaggler) (1.0.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->kaggler) (1.5.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow->kaggler) (56.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->kaggler) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->kaggler) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->kaggler) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->kaggler) (1.30.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->kaggler) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->kaggler) (1.0.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt->kaggler) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->statsmodels->kaggler) (2018.9)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->kaggler) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->kaggler) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->kaggler) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->kaggler) (4.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->kaggler) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->kaggler) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->kaggler) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->kaggler) (4.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow->kaggler) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->kaggler) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->kaggler) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRTusrITG015",
        "outputId": "becf741e-7e00-4d18-d64a-3a5a198362ed"
      },
      "source": [
        "import torch\n",
        "\n",
        "import torchvision\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "import torchvision.transforms as transforms  # data processing\n",
        "\n",
        "from torch.utils.data import DataLoader  # mini-batch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import kaggler\n",
        "from kaggler.preprocessing import LabelEncoder\n",
        "from kaggler.model import AutoLGB\n",
        "import kaggler\n",
        "import itertools \n",
        "import torch.nn as nn  # loss\n",
        "import time\n",
        "import statsmodels.api as sm\n",
        "import torch.optim as optim  # optimizer\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRzpIgQP3f_D",
        "outputId": "de83c184-88b6-444c-812a-3818d884832b"
      },
      "source": [
        "pip install --user lightgbm==3.1.1"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm==3.1.1 in /root/.local/lib/python3.7/site-packages (3.1.1)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.1.1) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.1.1) (1.4.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.1.1) (0.36.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm==3.1.1) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.1.1) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fgH1NuYvds9"
      },
      "source": [
        "#import required packages\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import gc\n",
        "from hyperopt import hp, tpe, Trials, STATUS_OK\n",
        "from hyperopt.fmin import fmin\n",
        "from hyperopt.pyll.stochastic import sample\n",
        "#optional but advised\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#GLOBAL HYPEROPT PARAMETERS\n",
        "NUM_EVALS = 1000 #number of hyperopt evaluation rounds\n",
        "N_FOLDS = 5 #number of cross-validation folds on data in each evaluation round\n",
        "\n",
        "#LIGHTGBM PARAMETERS\n",
        "LGBM_MAX_LEAVES = 2**11 #maximum number of leaves per tree for LightGBM\n",
        "LGBM_MAX_DEPTH = 25 #maximum tree depth for LightGBM\n",
        "EVAL_METRIC_LGBM_REG = 'mae' #LightGBM regression metric. Note that 'rmse' is more commonly used \n",
        "EVAL_METRIC_LGBM_CLASS = 'auc'#LightGBM classification metric\n",
        "\n",
        "#XGBOOST PARAMETERS\n",
        "XGB_MAX_LEAVES = 2**12 #maximum number of leaves when using histogram splitting\n",
        "XGB_MAX_DEPTH = 25 #maximum tree depth for XGBoost\n",
        "EVAL_METRIC_XGB_REG = 'mae' #XGBoost regression metric\n",
        "EVAL_METRIC_XGB_CLASS = 'auc' #XGBoost classification metric\n",
        "\n",
        "#CATBOOST PARAMETERS\n",
        "CB_MAX_DEPTH = 8 #maximum tree depth in CatBoost\n",
        "OBJECTIVE_CB_REG = 'MAE' #CatBoost regression metric\n",
        "OBJECTIVE_CB_CLASS = 'Logloss' #CatBoost classification metric\n",
        "\n",
        "#OPTIONAL OUTPUT\n",
        "BEST_SCORE = 0\n",
        "\n",
        "def quick_hyperopt(data, labels, package='lgbm', num_evals=NUM_EVALS, diagnostic=False):\n",
        "    \n",
        "    #==========\n",
        "    #LightGBM\n",
        "    #==========\n",
        "    \n",
        "    if package=='lgbm':\n",
        "        \n",
        "        print('Running {} rounds of LightGBM parameter optimisation:'.format(num_evals))\n",
        "        #clear space\n",
        "        gc.collect()\n",
        "        \n",
        "        integer_params = ['max_depth',\n",
        "                         'num_leaves',\n",
        "                          'max_bin',\n",
        "                         'min_data_in_leaf',\n",
        "                         'min_data_in_bin']\n",
        "        \n",
        "        def objective(space_params):\n",
        "            \n",
        "            #cast integer params from float to int\n",
        "            for param in integer_params:\n",
        "                space_params[param] = int(space_params[param])\n",
        "            \n",
        "            #extract nested conditional parameters\n",
        "            if space_params['boosting']['boosting'] == 'goss':\n",
        "                top_rate = space_params['boosting'].get('top_rate')\n",
        "                other_rate = space_params['boosting'].get('other_rate')\n",
        "                #0 <= top_rate + other_rate <= 1\n",
        "                top_rate = max(top_rate, 0)\n",
        "                top_rate = min(top_rate, 0.5)\n",
        "                other_rate = max(other_rate, 0)\n",
        "                other_rate = min(other_rate, 0.5)\n",
        "                space_params['top_rate'] = top_rate\n",
        "                space_params['other_rate'] = other_rate\n",
        "            \n",
        "            subsample = space_params['boosting'].get('subsample', 1.0)\n",
        "            space_params['boosting'] = space_params['boosting']['boosting']\n",
        "            space_params['subsample'] = subsample\n",
        "            \n",
        "            #for classification, set stratified=True and metrics=EVAL_METRIC_LGBM_CLASS\n",
        "            cv_results = lgb.cv(space_params, train, nfold = N_FOLDS, stratified=False,\n",
        "                                early_stopping_rounds=100, metrics=EVAL_METRIC_LGBM_REG, seed=42)\n",
        "            \n",
        "            best_loss = cv_results['l1-mean'][-1] #'l2-mean' for rmse\n",
        "            #for classification, comment out the line above and uncomment the line below:\n",
        "            #best_loss = 1 - cv_results['auc-mean'][-1]\n",
        "            #if necessary, replace 'auc-mean' with '[your-preferred-metric]-mean'\n",
        "            return{'loss':best_loss, 'status': STATUS_OK }\n",
        "        \n",
        "        train = lgb.Dataset(data, labels)\n",
        "                \n",
        "        #integer and string parameters, used with hp.choice()\n",
        "        boosting_list = [{'boosting': 'gbdt',\n",
        "                          'subsample': hp.uniform('subsample', 0.5, 1)},\n",
        "                         {'boosting': 'goss',\n",
        "                          'subsample': 1.0,\n",
        "                         'top_rate': hp.uniform('top_rate', 0, 0.5),\n",
        "                         'other_rate': hp.uniform('other_rate', 0, 0.5)}] #if including 'dart', make sure to set 'n_estimators'\n",
        "        metric_list = ['MAE', 'RMSE'] \n",
        "        #for classification comment out the line above and uncomment the line below\n",
        "        #metric_list = ['auc'] #modify as required for other classification metrics\n",
        "        objective_list_reg = ['huber', 'gamma', 'fair', 'tweedie']\n",
        "        objective_list_class = ['binary', 'cross_entropy']\n",
        "        #for classification set objective_list = objective_list_class\n",
        "        objective_list = objective_list_reg\n",
        "\n",
        "        space ={'boosting' : hp.choice('boosting', boosting_list),\n",
        "                'num_leaves' : hp.quniform('num_leaves', 2, LGBM_MAX_LEAVES, 1),\n",
        "                'max_depth': hp.quniform('max_depth', 2, LGBM_MAX_DEPTH, 1),\n",
        "                'max_bin': hp.quniform('max_bin', 32, 255, 1),\n",
        "                'min_data_in_leaf': hp.quniform('min_data_in_leaf', 1, 256, 1),\n",
        "                'min_data_in_bin': hp.quniform('min_data_in_bin', 1, 256, 1),\n",
        "                'min_gain_to_split' : hp.quniform('min_gain_to_split', 0.1, 5, 0.01),\n",
        "                'lambda_l1' : hp.uniform('lambda_l1', 0, 5),\n",
        "                'lambda_l2' : hp.uniform('lambda_l2', 0, 5),\n",
        "                'learning_rate' : hp.loguniform('learning_rate', np.log(0.005), np.log(0.2)),\n",
        "                'metric' : hp.choice('metric', metric_list),\n",
        "                'objective' : hp.choice('objective', objective_list),\n",
        "                'feature_fraction' : hp.quniform('feature_fraction', 0.5, 1, 0.01),\n",
        "                'bagging_fraction' : hp.quniform('bagging_fraction', 0.5, 1, 0.01)\n",
        "            }\n",
        "        \n",
        "        #optional: activate GPU for LightGBM\n",
        "        #follow compilation steps here:\n",
        "        #https://www.kaggle.com/vinhnguyen/gpu-acceleration-for-lightgbm/\n",
        "        #then uncomment lines below:\n",
        "        #space['device'] = 'gpu'\n",
        "        #space['gpu_platform_id'] = 0,\n",
        "        #space['gpu_device_id'] =  0\n",
        "\n",
        "        trials = Trials()\n",
        "        best = fmin(fn=objective,\n",
        "                    space=space,\n",
        "                    algo=tpe.suggest,\n",
        "                    max_evals=num_evals, \n",
        "                    trials=trials)\n",
        "                \n",
        "        #fmin() will return the index of values chosen from the lists/arrays in 'space'\n",
        "        #to obtain actual values, index values are used to subset the original lists/arrays\n",
        "        best['boosting'] = boosting_list[best['boosting']]['boosting']#nested dict, index twice\n",
        "        best['metric'] = metric_list[best['metric']]\n",
        "        best['objective'] = objective_list[best['objective']]\n",
        "                \n",
        "        #cast floats of integer params to int\n",
        "        for param in integer_params:\n",
        "            best[param] = int(best[param])\n",
        "        \n",
        "        print('{' + '\\n'.join('{}: {}'.format(k, v) for k, v in best.items()) + '}')\n",
        "        if diagnostic:\n",
        "            return(best, trials)\n",
        "        else:\n",
        "            return(best)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QMQt0zuvZu4"
      },
      "source": [
        "def check_duplicate(df, *args): #중복 체크\n",
        "  check_list = list(set(df.columns.tolist())- set(args))\n",
        "  \n",
        "  # 중복되는 데이터 모두 저장하는 데이터 프레임  [boolean Seires]\n",
        "  dup_pair_df = df.duplicated(subset=check_list, keep=False) # 모든 중복 샘플을 모두 True 처리 \n",
        "  \n",
        "  sum_dup = dup_pair_df.sum()# 중복 데이터 개수 확인\n",
        "  print(f\"{args}을(를) 제외하고 중복되는 데이터 개수는\", sum_dup, \"입니다\")\n",
        "  \n",
        "\n",
        "  # 중복이 있을 경우 해당 데이터들의 index 반환\n",
        "  if dup_pair_df.sum() != 0:\n",
        "    print(\"중복 데이터 비율:\", round((sum_dup/len(df)*100),2))\n",
        "    print()\n",
        "    return df.loc[dup_pair_df].index"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZZusaaEWfdM"
      },
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "def run_randomForest(X_train,X_test,y_train,y_test):  #변수선택기법 RF\n",
        "    clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs = -1)\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print('정확도 : ' , accuracy_score(y_test, y_pred))\n",
        "def run_LGBM(X_train,X_test,y_train,y_test):          #변수선택기법 LGBM\n",
        "    clf = LGBMClassifier(n_estimators=100, random_state=0, n_jobs = -1)\n",
        "    clf.fit(X_train,y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print('정확도 : ' , accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YFK3DfaG04B"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import log_loss\n",
        "import random\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGz3a0j-G06D"
      },
      "source": [
        "train=pd.read_csv('/content/drive/My Drive/train.csv')\n",
        "test=pd.read_csv('/content/drive/My Drive/test.csv')\n",
        "submit = pd.read_csv('/content/drive/My Drive/sample_submission.csv')\n",
        "train = train.drop(['index'], axis=1)\n",
        "test = test.drop(['index'], axis=1)\n",
        "train['DAYS_BIRTH'] = train.DAYS_BIRTH.apply(lambda x: abs(x))\n",
        "test['DAYS_BIRTH'] = test.DAYS_BIRTH.apply(lambda x: abs(x))\n",
        "train['begin_month'] = train.begin_month.apply(lambda x: abs(x))\n",
        "test['begin_month'] = test.begin_month.apply(lambda x: abs(x))\n",
        "train['DAYS_EMPLOYED'] = train.DAYS_EMPLOYED.apply(lambda x: abs(x))\n",
        "test['DAYS_EMPLOYED'] = test.DAYS_EMPLOYED.apply(lambda x: abs(x))"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTSqEBVE-BQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9732a9-3bc3-45c9-8a90-7feceea0c7a3"
      },
      "source": [
        "cat_cols = [x for x in train.columns if train[x].dtype == 'object']\n",
        "num_cols = [x for x in train.columns if x not in cat_cols  + ['credit']]\n",
        "num_cols.remove('DAYS_BIRTH')\n",
        "num_cols.remove('DAYS_EMPLOYED')\n",
        "num_cols.remove('begin_month')\n",
        "feature_cols = num_cols + cat_cols\n",
        "for col in ['DAYS_BIRTH']:\n",
        "    train[col] = train[col]/365\n",
        "    test[col] = train[col]/365\n",
        "for col in ['DAYS_EMPLOYED']:\n",
        "    train[col] = train[col]/365\n",
        "    test[col] = train[col]/365\n",
        "for col in ['begin_month']:\n",
        "    train[col] = train[col]/12\n",
        "    test[col] = train[col]/12\n",
        "lbe = LabelEncoder(min_obs=10)\n",
        "print(feature_cols)\n",
        "train[cat_cols] = lbe.fit_transform(train[cat_cols])\n",
        "test[cat_cols] = lbe.transform(test[cat_cols])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['child_num', 'income_total', 'FLAG_MOBIL', 'work_phone', 'phone', 'email', 'family_size', 'gender', 'car', 'reality', 'income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "KYVqC6FzpUhW",
        "outputId": "ea105c61-ac14-47ee-ceef-cd1394d2ef15"
      },
      "source": [
        "train"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>car</th>\n",
              "      <th>reality</th>\n",
              "      <th>child_num</th>\n",
              "      <th>income_total</th>\n",
              "      <th>income_type</th>\n",
              "      <th>edu_type</th>\n",
              "      <th>family_type</th>\n",
              "      <th>house_type</th>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>FLAG_MOBIL</th>\n",
              "      <th>work_phone</th>\n",
              "      <th>phone</th>\n",
              "      <th>email</th>\n",
              "      <th>occyp_type</th>\n",
              "      <th>family_size</th>\n",
              "      <th>begin_month</th>\n",
              "      <th>credit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>202500.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>38.079452</td>\n",
              "      <td>12.901370</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>247500.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>31.178082</td>\n",
              "      <td>4.219178</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>450000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52.293151</td>\n",
              "      <td>12.147945</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.833333</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>202500.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>41.336986</td>\n",
              "      <td>5.731507</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.083333</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>157500.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>41.197260</td>\n",
              "      <td>5.767123</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.166667</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26452</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>225000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33.093151</td>\n",
              "      <td>5.435616</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26453</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>41.893151</td>\n",
              "      <td>6.780822</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.916667</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26454</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>292500.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>27.621918</td>\n",
              "      <td>5.520548</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.083333</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26455</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>171000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>27.794521</td>\n",
              "      <td>0.293151</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.916667</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26456</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>81000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>53.613699</td>\n",
              "      <td>2.775342</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26457 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       gender  car  reality  ...  family_size  begin_month  credit\n",
              "0           0    0        1  ...          2.0     0.500000     1.0\n",
              "1           0    0        0  ...          3.0     0.416667     1.0\n",
              "2           1    1        0  ...          2.0     1.833333     2.0\n",
              "3           0    0        0  ...          2.0     3.083333     0.0\n",
              "4           0    1        0  ...          2.0     2.166667     2.0\n",
              "...       ...  ...      ...  ...          ...          ...     ...\n",
              "26452       0    0        1  ...          4.0     0.166667     1.0\n",
              "26453       0    0        0  ...          2.0     3.916667     2.0\n",
              "26454       0    1        1  ...          2.0     2.083333     2.0\n",
              "26455       1    0        0  ...          1.0     4.916667     2.0\n",
              "26456       0    0        1  ...          2.0     0.750000     2.0\n",
              "\n",
              "[26457 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0vPzjJ8I3bW"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train[num_cols] = scaler.fit_transform(train[num_cols])\n",
        "test[num_cols] = scaler.transform(test[num_cols])"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39Ua-MgGG08N"
      },
      "source": [
        "train_x=train.drop(['credit'],axis=1)\n",
        "train_y=train['credit']"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLbbRq1vsHX7"
      },
      "source": [
        "#lgbm_params = quick_hyperopt(X_train_rfe, train_y, 'lgbm', 100)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukk-ju1n58cv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b71890dc-c40c-498b-dcd3-8a831d862793"
      },
      "source": [
        "print(train_x)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       gender  car  reality  ...  occyp_type  family_size  begin_month\n",
            "0           0    0        1  ...           0    -0.214735     0.500000\n",
            "1           0    0        0  ...           1     0.876135     0.416667\n",
            "2           1    1        0  ...           4    -0.214735     1.833333\n",
            "3           0    0        0  ...           3    -0.214735     3.083333\n",
            "4           0    1        0  ...           4    -0.214735     2.166667\n",
            "...       ...  ...      ...  ...         ...          ...          ...\n",
            "26452       0    0        1  ...           2     1.967005     0.166667\n",
            "26453       0    0        0  ...           0    -0.214735     3.916667\n",
            "26454       0    1        1  ...           2    -0.214735     2.083333\n",
            "26455       1    0        0  ...           1    -1.305605     4.916667\n",
            "26456       0    0        1  ...          10    -0.214735     0.750000\n",
            "\n",
            "[26457 rows x 18 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCQjtFAXHB8-"
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=150)\n",
        "folds=[]\n",
        "for train_idx, valid_idx in skf.split(train_x, train_y):\n",
        "    folds.append((train_idx, valid_idx))\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI_NM3M-9cKH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "f3cf5d38-58f5-4336-8356-d725fe817a30"
      },
      "source": [
        "\n",
        "'''for index in range(1,19): #변수선택과정\n",
        "    rfe =RFE(RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1), n_features_to_select=index)\n",
        "    rfe.fit(X_train,y_train)\n",
        "    X_train_rfe=rfe.transform(X_train)\n",
        "    X_train_rfe=pd.DataFrame(X_train_rfe)\n",
        "    X_valid_rfe=rfe.transform(X_valid)\n",
        "    X_valid_rfe=pd.DataFrame(X_valid_rfe)\n",
        "    print('feature : ' , index,'\\n')\n",
        "    run_randomForest(X_train_rfe,X_valid_rfe,y_train,y_valid)'''\n",
        "    \n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"for index in range(1,19): #변수선택과정\\n    rfe =RFE(RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1), n_features_to_select=index)\\n    rfe.fit(X_train,y_train)\\n    X_train_rfe=rfe.transform(X_train)\\n    X_train_rfe=pd.DataFrame(X_train_rfe)\\n    X_valid_rfe=rfe.transform(X_valid)\\n    X_valid_rfe=pd.DataFrame(X_valid_rfe)\\n    print('feature : ' , index,'\\n')\\n    run_randomForest(X_train_rfe,X_valid_rfe,y_train,y_valid)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9XTfR96-1jE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473bb888-0a2f-4590-cb31-e62651ed1935"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "X_train=train_x.iloc[train_idx]\n",
        "y_train=train_y[train_idx]\n",
        "y_valid= train_y[valid_idx]\n",
        "X_valid = train_x.iloc[valid_idx]\n",
        "for index in range(1,19):  #변수선택과정\n",
        "    rfe=RFE(LGBMClassifier(n_estimators=100,random_state=0,n_jobs=-1), n_features_to_select=index)\n",
        "    rfe.fit(X_train,y_train)\n",
        "    X_train_rfe=rfe.transform(X_train)\n",
        "    X_train_rfe=pd.DataFrame(X_train_rfe)\n",
        "    X_valid_rfe=rfe.transform(X_valid)\n",
        "    X_valid_rfe=pd.DataFrame(X_valid_rfe)\n",
        "    print('feature : ' , index,'\\n')\n",
        "    run_LGBM(X_train_rfe,X_valid_rfe,y_train,y_valid)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature :  1 \n",
            "\n",
            "정확도 :  0.6414666414666415\n",
            "feature :  2 \n",
            "\n",
            "정확도 :  0.6471366471366471\n",
            "feature :  3 \n",
            "\n",
            "정확도 :  0.6528066528066528\n",
            "feature :  4 \n",
            "\n",
            "정확도 :  0.6958986958986959\n",
            "feature :  5 \n",
            "\n",
            "정확도 :  0.6964656964656964\n",
            "feature :  6 \n",
            "\n",
            "정확도 :  0.6981666981666982\n",
            "feature :  7 \n",
            "\n",
            "정확도 :  0.6977886977886978\n",
            "feature :  8 \n",
            "\n",
            "정확도 :  0.6977886977886978\n",
            "feature :  9 \n",
            "\n",
            "정확도 :  0.6996786996786997\n",
            "feature :  10 \n",
            "\n",
            "정확도 :  0.7004347004347005\n",
            "feature :  11 \n",
            "\n",
            "정확도 :  0.7011907011907011\n",
            "feature :  12 \n",
            "\n",
            "정확도 :  0.7000567000567001\n",
            "feature :  13 \n",
            "\n",
            "정확도 :  0.7006237006237006\n",
            "feature :  14 \n",
            "\n",
            "정확도 :  0.6991116991116991\n",
            "feature :  15 \n",
            "\n",
            "정확도 :  0.6994896994896995\n",
            "feature :  16 \n",
            "\n",
            "정확도 :  0.6994896994896995\n",
            "feature :  17 \n",
            "\n",
            "정확도 :  0.6994896994896995\n",
            "feature :  18 \n",
            "\n",
            "정확도 :  0.6994896994896995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA9s7lhMxHeo"
      },
      "source": [
        "lgb_params = {\n",
        "  'bagging_fraction': 0.51,\n",
        "  'boosting': 'goss',\n",
        "  'feature_fraction': 0.8200000000000001,\n",
        "  'lambda_l1': 2.0830165101593767,\n",
        "  'lambda_l2': 3.5899014619176066,\n",
        "  'learning_rate': 0.11565250641676775,\n",
        "  'max_bin': 98,\n",
        "  'max_depth': 11,\n",
        "  'metric': 'multi_logloss',\n",
        "  'min_data_in_bin': 151,\n",
        "  'min_data_in_leaf': 2,\n",
        "  'min_gain_to_split': 3.5100000000000002,\n",
        "  'num_leaves': 412,\n",
        "  'objective': 'multi_class',\n",
        "  'other_rate': 0.09514122787212262,\n",
        "  'top_rate': 0.19817258931181442\n",
        "}\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3JKj-rRHMpK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb6c13f4-5349-404e-9807-da5872034103"
      },
      "source": [
        "\n",
        "random.seed(42)\n",
        "\n",
        "rfe=RFE(LGBMClassifier(n_estimators=100,random_state=0,n_jobs=-1), n_features_to_select=10)\n",
        "lgb_models={}\n",
        "for fold in range(5):\n",
        "    print(f'===================================={fold+1}============================================')\n",
        "    train_idx, valid_idx = folds[fold]\n",
        "    X_train, X_valid, y_train, y_valid = train_x.iloc[train_idx].values, train_x.iloc[valid_idx].values,train_y[train_idx].values, train_y[valid_idx].values \n",
        "    #print(X_train.shape,X_valid.shape,y_train.shape)\n",
        "    rfe.fit(X_train,y_train)\n",
        "    X_train=rfe.transform(X_train)\n",
        "    X_train=pd.DataFrame(X_train)\n",
        "    X_valid=rfe.transform(X_valid)\n",
        "    X_valid=pd.DataFrame(X_valid)\n",
        "    lgb = LGBMClassifier(**lgb_params)\n",
        "    lgb.fit(X_train, y_train, \n",
        "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
        "            early_stopping_rounds=100,verbose=100)\n",
        "    lgb_models[fold]=lgb\n",
        "    print(f'================================================================================\\n\\n')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================================1============================================\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.691448\tvalid_1's multi_logloss: 0.77959\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\ttraining's multi_logloss: 0.691448\tvalid_1's multi_logloss: 0.77959\n",
            "================================================================================\n",
            "\n",
            "\n",
            "====================================2============================================\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.689429\tvalid_1's multi_logloss: 0.791676\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\ttraining's multi_logloss: 0.689429\tvalid_1's multi_logloss: 0.791676\n",
            "================================================================================\n",
            "\n",
            "\n",
            "====================================3============================================\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.691941\tvalid_1's multi_logloss: 0.779793\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\ttraining's multi_logloss: 0.691941\tvalid_1's multi_logloss: 0.779793\n",
            "================================================================================\n",
            "\n",
            "\n",
            "====================================4============================================\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.690517\tvalid_1's multi_logloss: 0.78244\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\ttraining's multi_logloss: 0.690517\tvalid_1's multi_logloss: 0.78244\n",
            "================================================================================\n",
            "\n",
            "\n",
            "====================================5============================================\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's multi_logloss: 0.690542\tvalid_1's multi_logloss: 0.782191\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[100]\ttraining's multi_logloss: 0.690542\tvalid_1's multi_logloss: 0.782191\n",
            "================================================================================\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTnfouGHHPny"
      },
      "source": [
        "test=rfe.transform(test)\n",
        "test=pd.DataFrame(test)\n",
        "submit.iloc[:,1:]=0\n",
        "for fold in range(5):\n",
        "    submit.iloc[:,1:] += lgb_models[fold].predict_proba(test)/5"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEwOY7zIHSIe"
      },
      "source": [
        "submit.to_csv('/content/drive/My Drive/sample_submission.csv', index=False) # 0.7272812144"
      ],
      "execution_count": 93,
      "outputs": []
    }
  ]
}